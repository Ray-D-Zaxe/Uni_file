> # ==============================================================================
> # R PRACTICAL 13: K-MEANS CLUSTERING AND ELBOW METHOD
> # Subject: Data Mining with R (Master's Level)
> # ==============================================================================
> 
> # 1. Install and Load necessary packages
> # cluster: Provides clustering algorithms and diagnostics.
> # ggplot2: For high-quality, professional visualization.
> # factoextra: Simplifies the extraction and visualization of factor analysis and clustering results.
> 
> # install.packages(c("cluster", "ggplot2", "factoextra")) 
> library(cluster)
> library(ggplot2)
> library(factoextra)
> 
> cat("\n--- PACKAGES LOADED ---\n")

--- PACKAGES LOADED ---
> 
> 
> # ------------------------------------------------------------------------------
> # 2. DATA PREPARATION
> # ------------------------------------------------------------------------------
> 
> # Use the 'iris' dataset and select only the numeric columns (1 to 4)
> # We store the data as a matrix for the K-means algorithm.
> data_to_cluster <- iris[, 1:4]
> 
> # Scaling the data is critical for K-means as it relies on Euclidean distance.
> # Scaling standardizes all variables to have a mean of 0 and SD of 1.
> data_scaled <- scale(data_to_cluster)
> 
> cat("\n--- DATA PREPARATION ---\n")

--- DATA PREPARATION ---
> print(head(data_scaled))
     Sepal.Length Sepal.Width Petal.Length Petal.Width
[1,]   -0.8976739  1.01560199    -1.335752   -1.311052
[2,]   -1.1392005 -0.13153881    -1.335752   -1.311052
[3,]   -1.3807271  0.32731751    -1.392399   -1.311052
[4,]   -1.5014904  0.09788935    -1.279104   -1.311052
[5,]   -1.0184372  1.24503015    -1.335752   -1.311052
[6,]   -0.5353840  1.93331463    -1.165809   -1.048667
> cat("Data scaled successfully.\n")
Data scaled successfully.
> 
> 
> # ------------------------------------------------------------------------------
> # 3. ELBOW METHOD TO FIND OPTIMAL K
> # The Elbow method plots the Total Within-Cluster Sum of Squares (WSS) 
> # against the number of clusters (k). The 'elbow' or bend indicates optimal k.
> # ------------------------------------------------------------------------------
> 
> cat("\n--- ELBOW METHOD CALCULATION ---\n")

--- ELBOW METHOD CALCULATION ---
> 
> # Use fviz_nbclust from factoextra, which automates the process.
> elbow_plot <- fviz_nbclust(
+   data_scaled, 
+   kmeans, 
+   method = "wss", 
+   k.max = 10 # Check k from 1 to 10
+ ) +
+   geom_vline(xintercept = 3, linetype = 2, color = "red") +
+   labs(title = "Elbow Method for Optimal k")
> 
> # Display the elbow plot
> print(elbow_plot) 
> # Note: For the iris dataset, the plot usually shows a clear bend at k=3.
> 
> optimal_k <- 3 # Based on the standard result for the iris dataset
> 
> 
> # ------------------------------------------------------------------------------
> # 4. PERFORM K-MEANS CLUSTERING
> # ------------------------------------------------------------------------------
> 
> cat("\n--- K-MEANS CLUSTERING (k=", optimal_k, ") ---\n")

--- K-MEANS CLUSTERING (k= 3 ) ---
> 
> # nstart = 25: Runs K-means 25 times and picks the best result (lowest WSS).
> # iter.max = 30: Maximum number of iterations for the algorithm.
> kmeans_result <- kmeans(data_scaled, centers = optimal_k, nstart = 25, iter.max = 30)
> 
> # Display the summary of the clustering result
> print(kmeans_result)
K-means clustering with 3 clusters of sizes 53, 47, 50

Cluster means:
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1  -0.05005221 -0.88042696    0.3465767   0.2805873
2   1.13217737  0.08812645    0.9928284   1.0141287
3  -1.01119138  0.85041372   -1.3006301  -1.2507035

Clustering vector:
  [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 1 1 1 2 1
 [59] 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 2 2 1 1 2
[117] 2 2 2 1 2 1 2 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 1 2 2 2 1 2 2 2 1 2 2 1

Within cluster sum of squares by cluster:
[1] 44.08754 47.45019 47.35062
 (between_SS / total_SS =  76.7 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss" "betweenss"    "size"        
[8] "iter"         "ifault"      
> 
> 
> # ------------------------------------------------------------------------------
> # 5. VISUALIZE THE CLUSTERS IN 2D
> # We use Principal Component Analysis (PCA) to reduce the 4 dimensions 
> # into 2 for a clear visual plot.
> # ------------------------------------------------------------------------------
> 
> cat("\n--- CLUSTER VISUALIZATION (PCA Reduction) ---\n")

--- CLUSTER VISUALIZATION (PCA Reduction) ---
> 
> cluster_plot <- fviz_cluster(
+   kmeans_result, 
+   data = data_scaled, 
+   palette = "jco",  # A nice color palette
+   ggtheme = theme_minimal(), 
+   main = paste("K-means Clustering Results (k =", optimal_k, ")")
+ )
> 
> # Display the 2D cluster visualization plot
> print(cluster_plot)
> cat("----------------------------------------------\n")
----------------------------------------------
> 